#!/usr/bin/env python3.5

# -------------- MODULE IMPORTS -----------------

from __future__ import absolute_import
from scipy import interp
from sklearn.model_selection import KFold
from random import shuffle, randint
from matplotlib import pyplot as plt
from __future__ import division
from __future__ import print_function
import tensorflow as tf
import numpy as np
import time
import os
import csv
import pandas as pd
import six
from sklearn.utils import shuffle as mutualShuf
from sklearn.preprocessing import normalize
from sklearn.metrics import roc_curve
import matplotlib
# Force matplotlib to not use any Xwindows backend. > Allows for remote execution.
matplotlib.use('Agg')

tf.logging.set_verbosity(tf.logging.INFO)

# ----------- DEFINE CUSTOM FUNCTIONS ------------


def std_error(results_list):
    """
    Returns the coefficient fo variation error

    """
    err = np.std(results_list)/np.sqrt(10)

    return err


def import_pickle(fileLocation):

    # Import dataframe
    path_60 = fileLocation
    df_60 = pd.read_pickle(path_60)

    # Separate pandas dataframe into classification and data arrays
    labels_data = df_60["Classification"].as_matrix()
    coil_data = df_60["Coil Data"].as_matrix()

    return labels_data, coil_data


def split_data(coil_data, labels_data):
    """
    Split data into healthy and ill types.
    """
    ill_data = []
    health_data = []

    for index, item in enumerate(labels_data):

        if item == 1:
            ill_data.append(coil_data[index])

        if item == 0:
            health_data.append(coil_data[index])

    return ill_data, health_data


def function_town(ill_array, health_array, shuffle=True):
    """
    Return the processed ecg_data and the labels_data. Also return arrays of ill and healthy ppts.
    If shuffle is true, shuffle data.
    """

    print("ill samples", len(ill_array))
    print("healthy samples", len(health_array))

    labels_data = []

    for i in np.arange(0, len(ill_array), 1):
        labels_data.append(1)

    for i in np.arange(0, len(health_array), 1):
        labels_data.append(0)

    ecg_data = np.reshape(np.append(ill_array, health_array), (-1, 15, 2000))

    if shuffle == True:
        labels_data, ecg_data = mutualShuf(
            np.array(labels_data), ecg_data, random_state=0)

    return np.array(ecg_data), labels_data


def cnn_model_fn(features, labels, mode, params):

    # ----------- MODEL ARCHITECTURE -----------------

    # needs reshaping with new data
    input_layer = tf.reshape(
        features["x"], [-1, 15, 2000, 1], name="input_layer")

    # Convolutional Layer # 1
    conv1 = tf.layers.conv2d(
        inputs=input_layer,
        filters=80,
        kernel_size=[15, params["kernel_size"]],
        padding="same",
        activation=tf.nn.relu,
        trainable=False,
        name="conv1")

    # Average activations of convolutional layer 1
    with tf.variable_scope('Activations_1'):
        average_density_1 = tf.reduce_mean(
            input_tensor=tf.reduce_sum(tf.cast((conv1 > 0), tf.float32),
                                       axis=[1, 2, 3]),
            name="average_density_1")

        tf.summary.scalar('AvergageDensity1', average_density_1)

    # Pooling Layers #1
    pool1 = tf.layers.max_pooling2d(
        inputs=conv1,
        pool_size=2,
        strides=2,
        name="pool1")

    # Convolutional Layer # 2
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=160,
        kernel_size=[15, params["kernel_size"]],
        padding="same",
        activation=tf.nn.leaky_relu,
        name="conv2")

    # Log the average activations of the second layer
    with tf.variable_scope('Activations_2'):
        average_density_2 = tf.reduce_mean(
            input_tensor=tf.reduce_sum(tf.cast((conv2 > 0), tf.float32),
                                       axis=[1, 2, 3]),
            name="average_density_2")
        tf.summary.scalar('AvergageDensity2', average_density_2)

    # Pooling layer # 2
    pool2 = tf.layers.max_pooling2d(
        inputs=conv2,
        pool_size=2,
        strides=2,
        name="pool2")

    # Dense Layer
    pool2_flat = tf.reshape(
        pool2, [-1, 160 * int(pool2.shape[1]) * int(pool2.shape[2])])

    dense = tf.layers.dense(
        inputs=pool2_flat,
        units=128,
        activation=tf.nn.relu,
        name="dense")

    dropout = tf.layers.dropout(
        inputs=dense,
        rate=0.4,
        training=mode == tf.estimator.ModeKeys.TRAIN)

    # Logits layer

    logits = tf.layers.dense(
        inputs=dropout,
        units=2,
        name="logits")

# --------------- MODEL OUTPUT STRUCTURES ----------------

    predictions = {

        # Generate Predictions (for PREDICT and EVAL mode)

        "classes": tf.argmax(input=logits, axis=1),

        # Add 'softmax_tensor' to the  graph. It is used for the
        # PREDICT by the 'logging_hook'

        "probabilities": tf.nn.softmax(logits, name="softmax_tensor")}

    if mode == tf.estimator.ModeKeys.PREDICT:
        # PREDICT OUTPUT MUST BE BEFORE ANY FUNCTION INVOLVING LABELS
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    with tf.variable_scope('Accuracy'):
        labelsOH = tf.one_hot(labels, 2)
        correct_prediction = tf.equal(
            tf.argmax(tf.nn.softmax(logits), 1), tf.argmax(labelsOH, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # log the accuracy
        tf.summary.scalar('training_accuracy', accuracy)

    # Calculate Loss

    with tf.variable_scope('Loss_Layer'):
        loss = tf.losses.sparse_softmax_cross_entropy(
            labels=labels, logits=logits)

    # Create a logging hook for training metrics

    train_logging_hook = tf.train.SummarySaverHook(
        save_steps=50,
        output_dir=params["dir"],
        summary_op=tf.summary.merge_all())

    # Load up the image maps for conv1 from a checkpoint of the sparse encoder
    if params["sparcity_constraint"] != -1:
        tf.train.init_from_checkpoint(params["checkpoint"],
                                      {'conv1/kernel': 'conv1/kernel',  # This overrides default initialization ops of specified variables.
                                       'conv1/bias': 'conv1/bias'})

    # Configure the training Op (for TRAIN mode)
    if mode == tf.estimator.ModeKeys.TRAIN:

        optimizer = tf.train.AdamOptimizer(
            learning_rate=1e-3)  # CHANGED FOR SPARSITY MODEL
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(
            mode=mode,
            loss=loss,
            train_op=train_op,
            training_hooks=[train_logging_hook])  # ADDED LOGGING HOOK

    # Add evaluation metric (for EVAL mode), These give final performance metrics.

    eval_metric_ops = {
        "final_accuracy": tf.metrics.accuracy(
            labels=labels, predictions=predictions["classes"]),  # Calculates how often the predictions matches the labels

        "roc_auc_score": tf.metrics.auc(
            labels=labels, predictions=predictions["classes"]),  # Computes the approximate AUC via a Riemann sum

        "sensativity": tf.metrics.true_positives(
            labels=labels, predictions=predictions["classes"]),  # Sum the weights of true-positives

        "false-positive (1 - specificity)": tf.metrics.false_positives(
            labels=labels, predictions=predictions["classes"]),  # Sum the weights of false-positives

        "precision": tf.metrics.precision(
            labels=labels, predictions=predictions["classes"])  # Computes the precision of the predictions with respect to the labels.
    }

    return tf.estimator.EstimatorSpec(
        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)


def main(unused_argv):

    # ------------------ DATA IMPORT --------------------
    initz = time.perf_counter()

    # File Directory
    dir = os.path.dirname(os.path.realpath(__file__))

    # File Name
    filename = str(os.path.basename(os.path.realpath(__file__))).split('.')[0]

    # Import data from pandas dataframe
    labels_data, coil_data = import_pickle("./inData/6060DataFrame.pkl")

    # Normalise coil_data
    for index, item in enumerate(coil_data):

        coil_data[index] = normalize(item, axis=1)

    # Split data into healthy and Ill so that equal amounts of both can be saved for evaluation
    ill_data, health_data = split_data(coil_data, labels_data)

    ill_unseen = np.array(ill_data[:20])
    health_unseen = np.array(health_data[:20])
    ill_data = np.array(ill_data[20:])
    health_data = np.array(health_data[20:])

    ecg_data, labels_data = function_town(ill_data, health_data, True)
    unseen_data, unseen_labels = function_town(ill_unseen, health_unseen, True)

    # Reshape data to fit into tensorflow placeholder
    ecg_data = np.reshape(ecg_data, (-1, 15, 2000, 1))
    unseen_data = np.reshape(unseen_data, (-1, 15, 2000, 1))

    # load training data and eval data
    eval_data = unseen_data.astype(np.float32)  # keep amounts of data the same
    train_data = ecg_data.astype(np.float32)
    eval_labels = unseen_labels.astype(np.int32)
    train_labels = labels_data.astype(np.int32)

    # combine full data fro k-fold cross validation methods
    full_data = np.append(train_data, eval_data, axis=0)
    full_labels = np.append(train_labels, eval_labels, axis=0)

# --------- NEURAL NETWORK OPERATIONS -------------------

    # Create a directory to store outputs and results
    results_dir = dir + '/Results/' + filename + '/'

    if not os.path.exists(results_dir):
        os.makedirs(results_dir)

    if not os.path.exists(results_dir + 'fold_summaries.csv'):
        # create a csv file to store output data from every run
        with open(results_dir + 'fold_summaries.csv', 'a+') as csvfile:
            results_writer = csv.writer(csvfile)
            results_writer.writerow(['Sparcity Constraint', 'Fold', 'Accuracy', 'Loss',
                                     'Roc Auc Score', 'Sensativity', 'Specificity', 'Precision', 'Training Time'])

    if not os.path.exists(results_dir + 'results_summary.csv'):
        # create csv file to store results summaries from K-fold X-validated summary
        with open(results_dir + 'results_summary.csv', 'a+') as csvfile:
            results_writer = csv.writer(csvfile)
            results_writer.writerow(['Sparcity Constraint', 'Accuracy', 'Loss',
                                     'Roc Auc Score', 'Sensativity', 'Specificity', 'Precision'])

    # Picked 3 best performing sparcity constraints (accuracy)
    for sc in [-1, 0.0, 0.0001, 9e-05, 0.00011, 0.001]:

        # Define folding strategy
        k_fold = KFold(
            n_splits=10,
            shuffle=False,  # already shuffled in function_towncat
            random_state=None)

        accuracy_list, loss_list, auc_list, sensativity_list, specificity_list, precision_list, tprs = [
        ], [], [], [], [], [], []
        mean_fpr = np.linspace(0, 1, 100)
        plt.figure()  # This creates a new figure for each sparcity constraint

        # Produces fold numbers and indecies
        for k, (train_index, test_index) in enumerate(k_fold.split(full_data, full_labels)):

            ker = 10

            model_dir = results_dir + 'sc-' + str(sc) + '/fold-' + str(k) + '/'

            # Location of directory containing sparse-encoded image map to pass through model_params
            checkpoint = dir + '/Results/2D-CNN-ECG-sparse-encoder/ker-' + \
                str(ker) + '/sc-' + str(sc) + '/'

            # Start performance counter
            start = time.perf_counter()

            # Make the results directory

            if not os.path.exists(model_dir):
                os.makedirs(model_dir)

            # Hyperparameters to pass to the

            model_params = {
                "sparcity_constraint": sc,
                "dir": model_dir,
                "checkpoint": checkpoint,
                "kernel_size": ker
            }

            # create the estimator

            ecg_classifier = tf.estimator.Estimator(
                model_fn=cnn_model_fn,
                model_dir=model_dir,
                params=model_params)

            # Set up logging for predictions
            tensors_to_log = {
                "probabilities": "softmax_tensor",
            }

            logging_hook = tf.train.LoggingTensorHook(
                tensors=tensors_to_log, every_n_iter=50)

            # Train the Model
            train_input_fn = tf.estimator.inputs.numpy_input_fn(
                x={"x": full_data[train_index]},
                y=full_labels[train_index],
                batch_size=10,
                num_epochs=None,
                shuffle=True)

            ecg_classifier.train(
                input_fn=train_input_fn,
                steps=20000,
                hooks=[logging_hook])

            # Evaluate the model and print results
            eval_input_fn = tf.estimator.inputs.numpy_input_fn(
                x={"x": full_data[test_index]},
                y=full_labels[test_index],
                num_epochs=1,
                shuffle=False)

            eval_results = ecg_classifier.evaluate(input_fn=eval_input_fn)


# ------------- RESULTS OUTPUTTING ----------------

            print(eval_results)

            # Finish performance counter
            finish = time.perf_counter()
            train_time = finish - start
            print("Total traintime: %.3f seconds" % train_time)

            fold_summary = [str(sc),
                            str(k),
                            '{:.8f}'.format(eval_results["final_accuracy"]),
                            '{:.8f}'.format(eval_results["loss"]),
                            '{:.8f}'.format(eval_results["roc_auc_score"]),
                            '{:.8f}'.format(eval_results["sensativity"]),
                            '{:.8f}'.format(
                (1.0 - eval_results["false-positive (1 - specificity)"])),
                '{:.8f}'.format(eval_results["precision"]),
                '{:.8f}'.format(train_time)]

            accuracy_list.append(eval_results["final_accuracy"])
            loss_list.append(eval_results["loss"])
            auc_list.append(eval_results["roc_auc_score"])
            sensativity_list.append(eval_results["sensativity"])
            specificity_list.append(
                1.0 - eval_results["false-positive (1 - specificity)"])
            precision_list.append(eval_results['precision'])

            with open(results_dir + 'fold_summaries.csv', 'a') as csvfile:
                results_writer = csv.writer(csvfile)
                results_writer.writerow(fold_summary)

            # Get predictions for roc curve
            pred_input_fn = tf.estimator.inputs.numpy_input_fn(
                x={"x": full_data[test_index]},
                y=None,
                num_epochs=1,
                shuffle=False)

            predictions = np.array(list((ecg_classifier.predict(
                input_fn=pred_input_fn, predict_keys='probabilities'))))

            # Sort predictions into the right shape and format
            class_predictions = []

            for i in range(predictions.shape[0]):
                class_predictions.append(
                    [predictions[i]['probabilities'][0], predictions[i]['probabilities'][1]])

            # numpy gives (2000,) but need (2000, 1) for sklearn
            class_predictions = np.reshape(
                np.array(class_predictions)[:, 1], (40, 1))

            # Get roc curve values
            fpr, tpr, th = roc_curve(np.reshape(
                full_labels[test_index], (40, 1)), class_predictions)

            tprs.append(interp(mean_fpr, fpr, tpr))
            tprs[-1][0] = 0.0

            # Add this fold to plot
            plt.plot(fpr, tpr, lw=1, alpha=0.3)

        # Add all folds roc curves into a plot with averages!

        # Plot the 'Luck' line
        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',
                 label='Luck', alpha=.8)

        # Plot the mean roc curve
        mean_tpr = np.mean(tprs, axis=0)
        mean_tpr[-1] = 1.0
        mean_auc = np.mean(auc_list)
        std_auc = np.std(auc_list)
        plt.plot(mean_fpr, mean_tpr, color='b',
                 label=r'Mean ROC (AUC - %0.2f $\pm$ %0.2f)' % (mean_auc, std_auc),
                 lw=2, alpha=.8)

        # Fill between the roc curves
        std_tpr = np.std(tprs, axis=0)
        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,
                         label=r'$\pm$ 1 std. dev.')

        # Make plot look pretty
        plt.xlim([-0.05, 1.05])
        plt.ylim([-0.05, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic, sc-'+str(sc))
        plt.legend(loc="lower right")
        plt.savefig(results_dir + 'ROC-sc-' + str(sc) + '.jpg')

        # Calculate cross validation and output to result summary file

        mean_results = [str(sc),
                        "{:.8f} $\pm$ {:.2%}".format(
                            np.mean(accuracy_list), std_error(accuracy_list)),
                        "{:.8f} $\pm$ {:.2%}".format(
                            np.mean(loss_list), std_error(loss_list)),
                        "{:.8f} $\pm$ {:.2%}".format(
                            np.mean(auc_list), std_error(auc_list)),
                        "{:.8f} $\pm$ {:.2%}".format(
                            np.mean(sensativity_list), std_error(sensativity_list)),
                        "{:.8f} $\pm$ {:.2%}".format(
                            np.mean(specificity_list), std_error(specificity_list)),
                        "{:.8f} $\pm$ {:.2%}".format(np.mean(precision_list), std_error(precision_list))]

        with open(results_dir + 'results_summary.csv', 'a') as csvfile:
            results_writer = csv.writer(csvfile)
            results_writer.writerow(mean_results)

    finz = time.perf_counter()
    total_run_time = finz - initz
    print('Total run time: {:.6f}'.format(total_run_time))
    print('Results:')

    with open(results_dir + 'results_summary.csv', 'r') as csvfile:
        results_reader = csv.reader(csvfile)
        for row in results_reader:
            print(row)
            print()


if __name__ == "__main__":
    tf.app.run()
